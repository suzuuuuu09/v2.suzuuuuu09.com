---
title: しゃどうぶろっかー
author: suzu
slug: shadow-blocker
tags:
  - Unity
  - Mediapipe
  - OpenCV
  - Python
thumbnail: "![[しゃどうぶろっかー-1763832978263.webp]]"
description: 「バーチャルな 2D アクションゲーム」と「リアルな身体の動きによる妨害」を融合させた新感覚の対戦アクションゲーム「しゃどうぶろっかー」。東京ゲームショー2025にて出展した。
isPublish: true
publishDate: 2025-12-01T17:50
updateDate: 2025-12-02T17:34
---
## 画像・動画
![[しゃどうぶろっかー-1763832978263.webp]]

![[20250928_153119.webm]]
## 概要
このゲームは**東京ゲームショー2025**(以下 TGS) にて出展し、100 人以上の方に遊んでいただきました。遊んでいただいた方から「ありそうでなかったゲーム」「身体を動かして妨害するのが楽しい」といった反応をいただきました。  
\
2D アクションのステージでゴールを目指す「**プレイヤー**」と、影（シャドウ）となってゲームに入り、プレイヤーをゴールさせないためにキックやパンチなどの身体動作で妨害する「**シャドウ**」の 2 人に分かれて戦います。「バーチャルな 2D アクションゲーム」と「リアルな身体の動きによる妨害」を融合させた新感覚の対戦アクションゲーム「しゃどうぶろっかー」です。  
\
チーム開発で私はゲームシステムと効果音などのサウンド面、トラッキングをおこなっているバックエンドを担当しました。

## 背景
私の所属している愛知工業大学では東京ゲームショーで自作したゲームを出展する学生プロジェクトが行われています。この学生プロジェクトでは、バーコードや障子などの日常にある一風変わったものをゲームインターフェース化する挑戦を続けています。そこで私たちは、「人間の身体そのもの」をゲームインターフェースにして直感的かつダイナミックに遊べるゲーム「しゃどうぶろっかー」を考えました。

## ゲーム内容
### 基本
このゲームは 2D アクションのステージでゴールを目指す「**プレイヤー**」と、影（シャドウ）となってゲームに入り、プレイヤーをゴールさせないためにキックやパンチなどの身体動作で妨害する「**シャドウ**」に分かれて戦います。  
制限時間は 100 秒です。100 秒以内にゴールできればプレイヤーの勝ち、100 秒以内にゴールさせなければシャドウの勝ちです。

### アイテム
アイテムには「バリアアイテム（一定時間キックやパンチの影響を受けなくなる）」と「ブーストアイテム（一定時間ジャンプ力が上がる）」の 2 種類がランダムでステージ上に出現します。
プレイヤーは、状況に合わせてアイテムを取得することが勝利のカギとなります。シャドウは、プレイヤーにアイテムを取らせないようにしましょう。

### プレイヤー
プレイヤーは、コントローラーでキャラクターを操作してゴールを目指します。途中でシャドウからの妨害を食らうと、キャラクターが飛んで一時的に操作ができなくなりますが、ステージのギミックを利用して諦めずにゴールしましょう。

### シャドウ
シャドウは、**Web カメラの前で**キックやパンチなどの全身を使った動きを行います。この動きを MeidaPipe でリアルタイムに検知し、その結果（キックやパンチなどの判定）に応じてプレイヤーキャラクターを吹き飛ばして一時的に操作不能にする「ブロッカー」として機能します。  
これを利用してシャドウはプレイヤーをゴールさせないようにしましょう。

## 技術スタック

- **ゲームエンジン**: Unity (C#)
- **トラッキング (姿勢推定)**: MediaPipe
- **カメラ処理**: OpenCV
- **バックエンド言語**: Python

## 技術的な工夫
### リアルタイム姿勢推定
[姿勢ランドマーク検出ガイド  \|  Google AI Edge  \|  Google AI for Developers](https://ai.google.dev/edge/mediapipe/solutions/vision/pose_landmarker?hl=ja)
リアルタイムの姿勢推定には Mediapipe を使用しました。Mediapipe は Google が開発したオープンソースのフレームワークで、カメラの映像や動画から顔や手などの全身の姿勢をリアルタイムで検出し、トラッキングをすることができます。  
 Mediapipe で取得したランドマークの加速度を計算し、ある一定の閾値を超えたらキックやパンチの身体動作を検知するようになっています。

### バックエンドに Python を採用した理由
ゲームエンジンの Unity は、グラフィック処理や物理演算などを行い、**常に安定したフレームレート (FPS) を維持する必要**があります。一方、Mediapipe を使用したリアルタイム姿勢推定は、**CPU / GPU に高負荷な処理**をします。TGS の展示では、**8 時間もの連続動作に耐えられるような安定性を保つ必要**がありました。  
そこで、私はトラッキング処理に Python を採用し、Unity とは独立した別プロセスの実行をすることで安定した処理を行えると考えました。これにより、Mediapipe 側が処理速度の遅延やフレームレートの低下が起きても、Unity 側のフレームレートを低下することなく、安定性を保ってゲームを実行できました。
### Python と Unity の通信
Python 側と Unity 側の通信は TCP 通信を用いて行っています。映っている人物を切り取って黒塗りにし、PNG 形式で Base64 にエンコードしたデータを Unity 側に送ります。Unity 側は送られたデータをデコードし、ゲーム内に画像として表示しています。これを連続で繰り返すことによって映像のように処理できます。